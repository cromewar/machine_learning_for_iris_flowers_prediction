{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad08ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55374c21",
   "metadata": {},
   "source": [
    "### Split the data on the training set and the test set\n",
    "\n",
    "\n",
    "**Training set and testing set**\n",
    "\n",
    "Machine learning is about learning some properties of a data set and then testing those properties against another data set. A common practice in machine learning is to evaluate an algorithm by splitting a data set into two. We call one of those sets the training set, on which we learn some properties; we call the other set the testing set, on which we test the learned properties.\n",
    "\n",
    "**X** corresponds to all the data which is given as input.\n",
    "\n",
    "**y** corressponds to all the results expected from **X**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117c63f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "### The names are the properties that the Ires flowers has\n",
    "# For Feature names we have all it's atributes \n",
    "#For the target names we have the species of each iris\n",
    "\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(feature_names)\n",
    "print(target_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ffde6",
   "metadata": {},
   "source": [
    "It's important to have the train shape bigger than the test shape, so our algorithm will have more data to learn from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60dd0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ab94e",
   "metadata": {},
   "source": [
    "### Creating The Model\n",
    "\n",
    "The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data \n",
    "\n",
    "### Nearest Neighbors Classification\n",
    "The k-neighbors classification in KNeighborsClassifier is the most commonly used technique. The optimal choice of the value k is highly data-dependent: in general a larger suppresses the effects of noise, but makes the classification boundaries less distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd715fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851aff7e",
   "metadata": {},
   "source": [
    "### Comparing the prediction with the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9ffd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
